####
## Output descriptions:
##

# Treasure Data (http://www.treasure-data.com/) provides cloud based data
# analytics platform, which easily stores and processes data from td-agent.
# FREE plan is also provided.
# @see http://docs.fluentd.org/articles/http-to-td
#
# This section matches events whose tag is td.DATABASE.TABLE

<source>
  @type tail
  path /var/log/ruby_on_rails.log
  pos_file /var/log/td-agent/ruby_on_rails.log.pos
  tag ruby_on_rails.log
  <parse>
    # https://docs.fluentd.org/parser/multiline
    @type multiline
    format_firstline /^Started/
    format1 /Started (?<method>[^ ]+) "(?<path>[^"]+)" for (?<host>[^ ]+) at (?<time>[^ ]+ [^ ]+ [^ ]+)\n/
    format2 /Processing by (?<controller>[^\u0023]+)\u0023(?<controller_method>[^ ]+) as (?<format>[^ ]+?)\n/
    format3 /(  Parameters: (?<parameters>[^ ]+)\n)?/
    format4 /  Rendered (?<template>[^ ]+) within (?<layout>.+) \([\d\.]+ms\)\n/
    format5 /Completed (?<code>[^ ]+) [^ ]+ in (?<runtime>[\d\.]+)ms \(Views: (?<view_runtime>[\d\.]+)ms \| ActiveRecord: (?<ar_runtime>[\d\.]+)ms\)/
  </parse>
</source>

<match ruby_on_rails.log>
  @type forest

  # https://docs.fluentd.org/output/s3
  subtype s3

  <template>
    # aws credentials
    aws_key_id XXXXXXXXXX
    aws_sec_key XXXXXXXXXX

    # S3 bucket/object path
    # https://docs.fluentd.org/output/s3
    s3_bucket XXXXXXXXX
    s3_region ap-northeast-1
    path logs/${tag_parts[0]}_${tag_parts[1]}/
    # s3_object_key_format "%{path}%{time_slice}/#{Socket.gethostname}_%{uuid_flush}_%{index}.%{file_extension}"
    s3_object_key_format "%{path}%{time_slice}/#{Socket.gethostname}_%{index}.%{file_extension}"
    time_slice_format %Y/%m/%d/%H/%M

    <format>
      @type json
    </format>

    ### Config: Buffer Section
    # https://tagomoris.hatenablog.com/entry/20130123/1358929254
    <buffer tag, time>
      # https://docs.fluentd.org/configuration/buffer-section
      # https://docs.fluentd.org/buffer/file
      @type file
      path /var/log/td-agent/buffer/${tag_parts[0]}_${tag_parts[1]}/

      # https://docs.fluentd.org/configuration/buffer-section#time
      timekey 3600
      timekey_use_utc true

      # inputでparseされたログ(multilineの場合は最後の行まで)のsizeより大きくしないといけない
      chunk_limit_size 300B

      ### Flushing Parameters
      # flush_mode:
      #   flush_intervalを使用するために 'interval' を明示指定する必要がある
      #   本パラメータを指定せずに flush_interval を指定しているとWarningが出る
      #   [warn]: #0 'flush_interval' is ignored because default 'flush_mode' is not 'interval': 'lazy'
      #
      # flush_interval:
      #   chunk を S3 (などのoutput) へ書き出す間隔
      #
      #   e.g.
      #     1分間に300Bytesのログを5回書き込むとchunkは5つ作成され、S3にも5つのobjectがputされる
      #     chunk_limit_size 300B
      #     flush_interval 60s
      #
      flush_mode interval
      flush_interval 60s

      # 2以上のthreadでchunkのflush/writeを行う場合は3 object keyに %{uuid_flush} を含めるのが推奨
      # [warn]: #0 No ${chunk_id} or %{uuid_flush} in s3_object_key_format with multiple flush threads.
      #         Recommend to set ${chunk_id} or %{uuid_flush} to avoid data lost by object conflict
      flush_thread_count 5

      # flush_at_shutdown
      #   fluentdシャットダウン時にmemory bufferをfileに書き出す処理
      #   s3 plugin 使用時、file bufferがキューイングされた状態になるがS3への転送はされていない
      #     Fluent::Plugin::S3Output が先にshutdownしているように見える
      #
      flush_at_shutdown true
    </buffer>
  </template>

</match>
